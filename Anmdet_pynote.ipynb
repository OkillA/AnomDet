{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import pywt\n",
    "import skimage.measure\n",
    "import mahotas as mt\n",
    "from skimage.filters import laplace, sobel, gabor_kernel, prewitt_h,prewitt_v\n",
    "#from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2hsv, rgb2gray, rgb2yuv\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865753fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anomdet:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('training instance start')\n",
    "\n",
    "                   \n",
    "        \n",
    "    def getdata(self,path,A):                                 # feature extraction. Array A acts like feature selector\n",
    "        images = os.listdir(path)\n",
    "        features=[]\n",
    "        for img in images:\n",
    "            feature = []\n",
    "            a = plt.imread(path+img,0)\n",
    "            img1 = cv2.resize(a, (224, 224))\n",
    "#            img_n1 = np.array(img1).copy()\n",
    "\n",
    "            b = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if A[0] == 1:\n",
    "\n",
    "                # Edge detection features using filters like laplace,sobel and prewitt \n",
    "\n",
    "                lap_feat = laplace(b)\n",
    "                sob_feat = sobel(b)\n",
    "\n",
    "                hpre_feat = prewitt_h(b)\n",
    "                vpre_feat = prewitt_v(b)\n",
    "                feature.extend([lap_feat.mean(),lap_feat.var(),np.amax(lap_feat),\n",
    "                                sob_feat.mean(),sob_feat.var(),np.max(sob_feat),hpre_feat.mean(),hpre_feat.var(),np.max(hpre_feat),vpre_feat.mean(),vpre_feat.var(),np.max(vpre_feat)])\n",
    "\n",
    "\n",
    "\n",
    "            if A[1] == 1:\n",
    "\n",
    "                # Haralick features\n",
    "\n",
    "                textures = mt.features.haralick(img1.astype(int))          \n",
    "                for i in textures:\n",
    "                    feature.extend(i) \n",
    "\n",
    "\n",
    "\n",
    "            if A[2] == 1:\n",
    "\n",
    "                # Oriented FAST and rotated BRIEF(ORB) features which replace the SIFT and SURF in recent versions of python\n",
    "\n",
    "                orb = cv2.ORB_create()\n",
    "                # find the keypoints with ORB\n",
    "                kp = orb.detect(img1,None)\n",
    "                # compute the descriptors with ORB\n",
    "                kp, des = orb.compute(img1, kp)\n",
    "        #         for d in des:\n",
    "        #              feature.extend([d.mean(),d.var(),np.amax(d)])\n",
    "                feature.extend([len(kp)])\n",
    "\n",
    "\n",
    "            if A[3] == 1:\n",
    "\n",
    "                # Histogram of Oriented Gradients(HOG)\n",
    "\n",
    "                fd, hog_image = hog(b, orientations=4, pixels_per_cell=(14,14),cells_per_block=(1,1), visualize=True)\n",
    "                c=0\n",
    "                for i in fd:\n",
    "                    b[c] = i/np.linalg.norm(fd)\n",
    "                    c +=1\n",
    "#                         feature.extend(i)\n",
    "                feature.extend(c)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if A[4] == 1:\n",
    "\n",
    "                # DWT of the image and using the energy of patches of the image\n",
    "\n",
    "                coeffs2 = pywt.dwt2(b, 'db1')\n",
    "                LL, (LH, HL, HH) = coeffs2\n",
    "                for i in [LL,LH,HL,HH]:\n",
    "                    op=skimage.measure.block_reduce(i, (14,14), np.linalg.norm)\n",
    "                    op1 = i/np.linalg.norm(op)\n",
    "                    feature.append(op1)\n",
    "\n",
    "\n",
    "#                 if A[5] == 1:     # Removed from opensource in the recent versions of cv2\n",
    "\n",
    "#                     sift = cv2.SIFT_create()\n",
    "#                     keypoints, descriptors= sift.detectAndCompute(b, None)\n",
    "#                     for k in descriptors:\n",
    "#                         feature.extend([k.mean(),k.var(),np.amax(k)])    \n",
    "\n",
    "\n",
    "\n",
    "#                 if A[6] == 1:       # Fourier data\n",
    "#                     fft_image = np.fft.fft(image)\n",
    "#                     fft_data.append(fft_image)\n",
    "\n",
    "#                     freq  = np.fft.fftfreq(np.array(image).shape[-1], d=0.01)\n",
    "#                     fft_freq.append(freq )\n",
    "\n",
    "#                     fft_ps = np.abs(fft_image)**2\n",
    "#                     power_spec.append(fft_ps)\n",
    "\n",
    "#                     feature.extend([fft_data, fft_freq, power_spec])\n",
    "\n",
    "\n",
    "            features.append(feature)\n",
    "    \n",
    "        return features\n",
    "\n",
    "\n",
    "\n",
    "    # Training SVDD       \n",
    "    def svdtrain(self,all_features):\n",
    "        self.osvm_model = svm.OneClassSVM(nu=0.001,kernel='sigmoid')\n",
    "        self.osvm_model.fit(all_features)\n",
    "        \n",
    "        \n",
    "    # Training GLOSH    \n",
    "    def glosh(self):\n",
    "        self.clusters = hdbscan.HDBSCAN(min_cluster_size=100)\n",
    "        self.clusters.fit(self.all_features)\n",
    "        \n",
    "    \n",
    "    # Training XGBRegressor. Unlike svdd and glosh xgbr performs well with balanced data sets \n",
    "    def xgbrl(self):\n",
    "        self.lab = np.concatenate((np.ones((self.n_of_good, )), np.zeros((self.n_of_bad, ))), axis=0)\n",
    "        data_dmatrix = xgb.DMatrix(data=self.all_features,label=self.lab)\n",
    "        \n",
    "        \n",
    "        # Parameter dictionary specifying base learner\n",
    "        param = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "         \n",
    "        self.xgb_r = xgb.train(params = param, dtrain = data_dmatrix, num_boost_round = 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c418f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple SVDD with multiple feture sets as inputs\n",
    "\n",
    "# Instance with training and test data sets as inputs\n",
    "a1 = Anomdet()\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[1,1,1,0,1])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[1,1,1,0,1])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata=[]\n",
    "g1 = len(os.listdir(\"fin_data/goodt/\"))\n",
    "b1 = len(os.listdir(\"fin_data/badt/\"))\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[1,1,1,0,1])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[1,1,1,0,1])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "# Predicting with the test features\n",
    "temp = []\n",
    "temp = a1.osvm_model.predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred1 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# actual labels for the images \n",
    "truth = np.concatenate((np.ones((g1, )), np.zeros((b1, ))), axis=0)\n",
    "\n",
    "# Performance\n",
    "print('Accuracy:',accuracy_score(pred1,truth))\n",
    "print('Confusion matrix:\\n',confusion_matrix(pred1,truth))\n",
    "\n",
    "# to predict over a dataset y\n",
    "\n",
    "preddata = a1.getdata(\"fin_data/trial/\",[1,1,1,0,1])\n",
    "imagepred_df = pd.DataFrame(preddata)\n",
    "imagepred_df.drop(0,axis=1,inplace=True)\n",
    "allpred_features = np.array(imagepred_df)\n",
    "\n",
    "# Predicting with the test features\n",
    "predicty = []\n",
    "predicty = a1.osvm_model.predict(allpred_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred1 = [0 if i==-1 else 1 for i in predicty]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple GLOSH with multiple feture sets as inputs\n",
    "\n",
    "# Instance with training and test data sets as inputs\n",
    "a2 = Anomdet()\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a2.getdata(\"fin_data/good/\",[1,1,1,0,1])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a2.getdata(\"fin_data/bad/\",[1,1,1,0,1])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a2.glosh(alltrain_features)\n",
    "\n",
    "testdata=[]\n",
    "g1 = len(os.listdir(\"fin_data/goodt/\"))\n",
    "b1 = len(os.listdir(\"fin_data/badt/\"))\n",
    "goodtdata = a2.getdata(\"fin_data/goodt/\",[1,1,1,0,1])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a2.getdata(\"fin_data/badt/\",[1,1,1,0,1])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "\n",
    "# Predicting with the test features\n",
    "temp = []\n",
    "temp = a2.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred1 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# actual labels for the images \n",
    "truth = np.concatenate((np.ones((g1, )), np.zeros((b1, ))), axis=0)\n",
    "\n",
    "# Performance\n",
    "print('Accuracy:',accuracy_score(pred1,truth))\n",
    "print('Confusion matrix:\\n',confusion_matrix(pred1,truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual feature extraction for ensmeble models\n",
    "a1 = Anomdet()\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[1,0,0,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[1,0,0,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata=[]\n",
    "g1 = len(os.listdir(\"fin_data/goodt/\"))\n",
    "b1 = len(os.listdir(\"fin_data/badt/\"))\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[1,0,0,0,0])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[1,0,0,0,0])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred1 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred6 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,1,0,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,1,0,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[0,1,0,0,0])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[0,1,0,0,0])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred2 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred7 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,1,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,1,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[0,0,1,0,0])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[0,0,1,0,0])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred3 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred8 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,0,1,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,0,1,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[0,0,0,1,0])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[0,0,0,1,0])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred4 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred9 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,0,0,1])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,0,0,1])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "goodtdata = a1.getdata(\"fin_data/goodt/\",[0,0,0,0,1])\n",
    "testdata = testdata.append(goodtdata)\n",
    "badtdata = a1.getdata(\"fin_data/badt/\",[0,0,0,0,1])\n",
    "testdata = testdata.append(badtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred5 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred10 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# actual labels for the images \n",
    "truth = np.concatenate((np.ones((g1, )), np.zeros((b1, ))), axis=0)\n",
    "\n",
    "# Performance\n",
    "print('Accuracy:',accuracy_score(pred1,truth))\n",
    "print('Confusion matrix:\\n',confusion_matrix(pred1,truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating training data dor ensemble\n",
    "ensfeat = []\n",
    "for i in range(a1.total_test_num):\n",
    "    temp = [pred1[i],pred2[i],pred3[i],pred4[i],pred5[i],pred6[i],pred7[i],pred8[i],pred9[i],pred10[i]]\n",
    "    ensfeat.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf67d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ensemble takes outputs from individual classifiers and their respective labels  as inputs \n",
    "\n",
    "class EnsmebleMod:\n",
    "    def __init__(self, preds, truths):\n",
    "        self.preds = preds\n",
    "        self.truths = truths\n",
    "    \n",
    "    # Multilayer perceptron as an ensemble\n",
    "    def mlpc(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.preds, self.truths, test_size=0.2, random_state=3)\n",
    "        self.clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "        self.clf.fit(X_train,y_train)\n",
    "        finpreds = self.clf.predict(X_test)\n",
    "\n",
    "\n",
    "        print('Accuracy:',accuracy_score(finpreds,y_test))\n",
    "        print('Confusion matrix:\\n',confusion_matrix(finpreds,y_test))\n",
    "        \n",
    "    \n",
    "    # xgboost as an ensemble\n",
    "    def xgbr(self):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.preds, self.truths, test_size=0.2, random_state=123)\n",
    "        # Train and test set are converted to DMatrix objects,\n",
    "        # as it is required by learning API.\n",
    "        train_dmatrix = xgb.DMatrix(data = X_train, label = y_train)\n",
    "        test_dmatrix = xgb.DMatrix(data = X_test, label = y_test)\n",
    "        \n",
    "        # Parameter dictionary specifying base learner\n",
    "        param = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "         \n",
    "        self.xgb_r = xgb.train(params = param, dtrain = train_dmatrix, num_boost_round = 10)\n",
    "        xgpred = self.xgb_r.predict(test_dmatrix)\n",
    "\n",
    "        print('Accuracy:',accuracy_score(xgpred,y_test))\n",
    "        print('Confusion matrix:\\n',confusion_matrix(xgpred,y_test))\n",
    "        \n",
    "    # Bagging    \n",
    "    def bagg(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.preds, self.truths, test_size=0.2, random_state=123)\n",
    "        base_cls = DecisionTreeClassifier()\n",
    "        self.model = BaggingClassifier(base_estimator = base_cls, n_estimators = 500, random_state = 8)\n",
    "        self.model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb076075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of EnsembleMod\n",
    "e1 = EnsmebleMod(ensfeat, truth)\n",
    "\n",
    "# NN ensemble\n",
    "e1.mlpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual feature extraction for ensmeble models\n",
    "a3 = Anomdet()\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[1,0,0,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[1,0,0,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata=[]\n",
    "g1 = len(os.listdir(Y))\n",
    "\n",
    "testdata = a1.getdata(Y,[1,0,0,0,0])\n",
    "\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred1 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred6 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,1,0,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,1,0,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata = a1.getdata(Y,[0,1,0,0,0])\n",
    "testdata = testdata.append(goodtdata)\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred2 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred7 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,1,0,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,1,0,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata = a1.getdata(Y,[0,0,1,0,0])\n",
    "\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred3 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred8 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,0,1,0])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,0,1,0])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata = a1.getdata(Y,[0,0,0,1,0])\n",
    "\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred4 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred9 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Feature selector given in the form of an array\n",
    "traindata=[]\n",
    "gooddata = a1.getdata(\"fin_data/good/\",[0,0,0,0,1])\n",
    "traindata = traindata.append(gooddata)\n",
    "baddata = a1.getdata(\"fin_data/bad/\",[0,0,0,0,1])\n",
    "traindata = traindata.append(baddata)\n",
    "\n",
    "image_df = pd.DataFrame(traindata)\n",
    "image_df.drop(0,axis=1,inplace=True)\n",
    "alltrain_features = np.array(image_df)\n",
    "\n",
    "# Fitting an svdd with the given training data \n",
    "a1.svdtrain(alltrain_features)\n",
    "\n",
    "testdata = a1.getdata(Y,[0,0,0,0,1])\n",
    "\n",
    "\n",
    "\n",
    "imaget_df = pd.DataFrame(testdata)\n",
    "imaget_df.drop(0,axis=1,inplace=True)\n",
    "alltest_features = np.array(imaget_df)\n",
    "\n",
    "\n",
    "temp = []\n",
    "temp = a1.svm_model.predict(a1.alltest_features)\n",
    "\n",
    "pred5 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "# Fitting an glosh with the given training data \n",
    "a1.glosh(alltrain_features)\n",
    "temp = []\n",
    "temp = a1.clusters.fit_predict(alltest_features)\n",
    "# Since outliers are labeled as -1 in svdd and glosh\n",
    "pred10 = [0 if i==-1 else 1 for i in temp]\n",
    "\n",
    "ensfeat = []\n",
    "for i in range(a1.total_test_num):\n",
    "    temp = [pred1[i],pred2[i],pred3[i],pred4[i],pred5[i],pred6[i],pred7[i],pred8[i],pred9[i],pred10[i]]\n",
    "    ensfeat.append(temp)\n",
    "\n",
    "# Performance\n",
    "print('Accuracy:',accuracy_score(pred1,truth))\n",
    "print('Confusion matrix:\\n',confusion_matrix(pred1,truth))\n",
    "\n",
    "# To predict anomalous images in a dataset Y\n",
    "prediction = e1.clf.predict(ensfeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
